{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6d9dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Установка библиотек\n",
    "!pip install diffusers transformers accelerate safetensors torchvision matplotlib\n",
    "!pip install peft  # Для LoRA (если нужно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acecec0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "\n",
    "# Загрузка модели (может занять 5-10 минут)\n",
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Генерация изображения\n",
    "prompt = \"A realistic cat with green eyes, 4K, detailed fur\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(\"sdxl_output.png\")\n",
    "image  # Показать изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52626e62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import random\n",
    "\n",
    "# Гиперпараметры\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "latent_dim = 100\n",
    "img_size = 64\n",
    "channels = 3\n",
    "epochs = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Создание папок\n",
    "os.makedirs(\"gan_images\", exist_ok=True)\n",
    "os.makedirs(\"data/coco\", exist_ok=True)\n",
    "\n",
    "# Трансформации\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Класс для загрузки COCO\n",
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annFile)\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_url = img_info['coco_url']\n",
    "        \n",
    "        response = requests.get(img_url)\n",
    "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, 0  # Возвращаем 0 как фиктивный лейбл\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "# Загрузка COCO (если файлов нет, они скачаются автоматически)\n",
    "if not os.path.exists(\"data/coco/annotations_trainval2017.zip\"):\n",
    "    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P data/coco\n",
    "    !unzip data/coco/annotations_trainval2017.zip -d data/coco\n",
    "\n",
    "# Создаем датасет (будет загружать изображения по URL)\n",
    "dataset = CocoDataset(\n",
    "    root=\"data/coco\",\n",
    "    annFile=\"data/coco/annotations/instances_train2017.json\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Фильтруем датасет (берем только первые 5000 изображений для ускорения)\n",
    "dataset.ids = dataset.ids[:5000]\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Генератор\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Дискриминатор\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1)\n",
    "\n",
    "# Инициализация моделей\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Оптимизаторы\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Функция потерь\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Фиксированный шум для визуализации\n",
    "fixed_noise = torch.randn(64, latent_dim, 1, 1, device=device)\n",
    "\n",
    "# Обучение\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # Реальные и фейковые метки\n",
    "        real = torch.ones(imgs.size(0), device=device)\n",
    "        fake = torch.zeros(imgs.size(0), device=device)\n",
    "        \n",
    "        real_imgs = imgs.to(device)\n",
    "        \n",
    "        # Обучение дискриминатора\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Потери на реальных изображениях\n",
    "        output_real = discriminator(real_imgs)\n",
    "        loss_real = criterion(output_real, real)\n",
    "        \n",
    "        # Генерация фейковых изображений\n",
    "        noise = torch.randn(imgs.size(0), latent_dim, 1, 1, device=device)\n",
    "        fake_imgs = generator(noise)\n",
    "        \n",
    "        # Потери на фейковых изображениях\n",
    "        output_fake = discriminator(fake_imgs.detach())\n",
    "        loss_fake = criterion(output_fake, fake)\n",
    "        \n",
    "        # Общие потери дискриминатора\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Обучение генератора\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Потери генератора\n",
    "        output = discriminator(fake_imgs)\n",
    "        loss_G = criterion(output, real)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Логирование\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {loss_D.item():.4f}] [G loss: {loss_G.item():.4f}]\")\n",
    "    \n",
    "    # Сохранение сгенерированных изображений\n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = generator(fixed_noise).detach().cpu()\n",
    "        save_image(fake, f\"gan_images/epoch_{epoch}.png\", nrow=8, normalize=True)\n",
    "\n",
    "# Сохранение весов генератора\n",
    "torch.save(generator.state_dict(), \"generator_coco.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1e1f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Генератор\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Загрузка предобученного генератора (пример весов)\n",
    "generator = Generator().to(\"cuda\")\n",
    "generator.load_state_dict(torch.load(\"generator_coco.pth\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfcc81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Преобразование изображения от SDXL для DCGAN\n",
    "def preprocess_image(pil_image, size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    return transform(pil_image).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "# Улучшение изображения\n",
    "input_image = preprocess_image(image)\n",
    "with torch.no_grad():\n",
    "    enhanced = generator(input_image)\n",
    "\n",
    "# Визуализация\n",
    "def show_image(tensor):\n",
    "    tensor = tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    tensor = (tensor * 127.5 + 127.5).astype(\"uint8\")\n",
    "    plt.imshow(tensor)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Original (SDXL):\")\n",
    "show_image(input_image)\n",
    "\n",
    "print(\"Enhanced (DCGAN):\")\n",
    "show_image(enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc478b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Дополнительные импорты\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Загрузка COCO (пример)\n",
    "!wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!unzip train2017.zip\n",
    "\n",
    "# Датасет и загрузчик\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = ImageFolder(\"train2017\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Обучение\n",
    "def train_dcgan(epochs=10):\n",
    "    generator = Generator().to(\"cuda\")\n",
    "    discriminator = Discriminator().to(\"cuda\")\n",
    "    opt_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    opt_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for real_imgs, _ in dataloader:\n",
    "            real_imgs = real_imgs.to(\"cuda\")\n",
    "            noise = torch.randn(real_imgs.size(0), 100, 1, 1, device=\"cuda\")\n",
    "            fake_imgs = generator(noise)\n",
    "\n",
    "            # Обновление дискриминатора\n",
    "            opt_d.zero_grad()\n",
    "            real_loss = criterion(discriminator(real_imgs), torch.ones_like(discriminator(real_imgs)))\n",
    "            fake_loss = criterion(discriminator(fake_imgs.detach()), torch.zeros_like(discriminator(fake_imgs)))\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "            # Обновление генератора\n",
    "            opt_g.zero_grad()\n",
    "            g_loss = criterion(discriminator(fake_imgs), torch.ones_like(discriminator(fake_imgs)))\n",
    "            g_loss.backward()\n",
    "            opt_g.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
    "\n",
    "    torch.save(generator.state_dict(), \"generator.pth\")\n",
    "\n",
    "train_dcgan(epochs=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471a7ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Сохранить генератор\n",
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "\n",
    "# Загрузить в будущем\n",
    "generator = Generator().to(\"cuda\")\n",
    "generator.load_state_dict(torch.load(\"generator.pth\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
